{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPPWqfv7XXvej+4sXdxrwY2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Engenharia de Features\n","\n","A Engenharia de Features é o processo de transformar dados brutos em features (variáveis) que melhor representam o problema para modelos de machine learning. Neste material, vamos focar em três técnicas essenciais:\n","\n","- **Normalização**: Transformar variáveis numéricas para uma escala comum.\n","- **Codificação**: Transformar variáveis categóricas em representações numéricas.\n","- **Seleção de Variáveis**: Escolher as features mais relevantes para o modelo.\n","\n"],"metadata":{"id":"MbkI6dbQKyN6"}},{"cell_type":"markdown","source":["## Normalizaçao\n","\n","A normalização é usada para transformar variáveis numéricas em uma escala comum, o que é especialmente importante para algoritmos sensíveis à magnitude dos dados, como Regressão Linear.\n","\n","<br/>\n","\n","**Técnicas Comuns de Normalização**\n","\n","**Min-Max Scaling:** Transforma os valores para um intervalo específico (geralmente [0, 1]).\n","\n","**Standardization (Z-score):** Transforma os valores para ter média 0 e desvio padrão 1.\n","\n","Exemplo de código:\n"],"metadata":{"id":"xUlJWCTRLDS1"}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","import pandas as pd\n","\n","# Dados de exemplo\n","data = {'age': [25, 45, 35, 50, 23],\n","        'salary': [50000, 100000, 75000, 120000, 40000]}\n","df = pd.DataFrame(data)\n","\n","# Min-Max Scaling\n","scaler = MinMaxScaler()\n","df_minmax = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n","print(\"Min-Max Scaling:\\n\", df_minmax)\n","\n","# Standardization (Z-score)\n","scaler = StandardScaler()\n","df_standard = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n","print(\"Standardization:\\n\", df_standard)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGe-wX4CLBPe","executionInfo":{"status":"ok","timestamp":1739364128806,"user_tz":180,"elapsed":2343,"user":{"displayName":"Karoline Farias","userId":"07244923965688739469"}},"outputId":"5791868b-67cd-4133-912e-c83a6905af56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Min-Max Scaling:\n","         age  salary\n","0  0.074074  0.1250\n","1  0.814815  0.7500\n","2  0.444444  0.4375\n","3  1.000000  1.0000\n","4  0.000000  0.0000\n","Standardization:\n","         age    salary\n","0 -0.995228 -0.902007\n","1  0.882561  0.768376\n","2 -0.056334 -0.066815\n","3  1.352008  1.436529\n","4 -1.183007 -1.236083\n"]}]},{"cell_type":"markdown","source":["## Codificação\n","\n","Variáveis categóricas precisam ser transformadas em números para que modelos de machine learning possam processá-las. As técnicas mais comuns são:\n","\n","<br/>\n","\n","**Label Encoding:** Transforma cada categoria em um número inteiro.\n","\n","**One-Hot Encoding:** Cria colunas binárias para cada categoria.\n","\n","Exemplo de Código:\n"],"metadata":{"id":"cQU0_2eCL-v2"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import pandas as pd\n","\n","# Dados de exemplo\n","data = {'color': ['red', 'blue', 'green', 'blue', 'red']}\n","df = pd.DataFrame(data)\n","\n","# Label Encoding\n","label_encoder = LabelEncoder()\n","df['color_label'] = label_encoder.fit_transform(df['color'])\n","print(\"Label Encoding:\\n\", df)\n","\n","# One-Hot Encoding\n","onehot_encoder = OneHotEncoder(sparse_output=False)\n","onehot_encoded = onehot_encoder.fit_transform(df[['color']])\n","df_onehot = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(['color']))\n","print(\"One-Hot Encoding:\\n\", df_onehot)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SF7hyPkTLihE","executionInfo":{"status":"ok","timestamp":1739364586427,"user_tz":180,"elapsed":260,"user":{"displayName":"Karoline Farias","userId":"07244923965688739469"}},"outputId":"4fee9d98-8dde-4348-b5b8-157b5967409b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Label Encoding:\n","    color  color_label\n","0    red            2\n","1   blue            0\n","2  green            1\n","3   blue            0\n","4    red            2\n","One-Hot Encoding:\n","    color_blue  color_green  color_red\n","0         0.0          0.0        1.0\n","1         1.0          0.0        0.0\n","2         0.0          1.0        0.0\n","3         1.0          0.0        0.0\n","4         0.0          0.0        1.0\n"]}]},{"cell_type":"markdown","source":["## Seleção de Variáveis\n","\n","A seleção de variáveis ajuda a escolher as features mais relevantes para o modelo, reduzindo a dimensionalidade e melhorando o desempenho.\n","\n","<br/>\n","\n","**Técnicas Comuns de Seleção de Variáveis**\n","\n","**Correlação:** Selecionar variáveis com alta correlação com o target.\n","\n","**Importância de Features:** Usar modelos como árvores de decisão para medir a importância das features.\n","\n","**Seleção Recursiva de Features:** Selecionar features iterativamente com base no desempenho do modelo.\n","\n","Exemplo de Código"],"metadata":{"id":"dK1PvxigOH6q"}},{"cell_type":"code","source":["from sklearn.feature_selection import SelectKBest, f_classif\n","from sklearn.ensemble import RandomForestClassifier\n","import pandas as pd\n","import seaborn as sns\n","\n","# Dados de exemplo (Iris Dataset)\n","df = sns.load_dataset('iris')\n","X = df.drop(columns='species')\n","y = df['species']\n","\n","# Seleção baseada em correlação (apenas para variáveis numéricas)\n","corr = X.corrwith(pd.Series(pd.factorize(y)[0]))\n","print(\"Correlação com o target:\\n\", corr)\n","\n","# Seleção usando SelectKBest (teste estatístico)\n","selector = SelectKBest(score_func=f_classif, k=2)\n","X_selected = selector.fit_transform(X, y)\n","print(\"Features selecionadas (SelectKBest):\\n\", X.columns[selector.get_support()])\n","\n","# Seleção usando importância de features (RandomForest)\n","model = RandomForestClassifier()\n","model.fit(X, y)\n","importance = model.feature_importances_\n","print(\"Importância das features (RandomForest):\\n\", pd.Series(importance, index=X.columns))"],"metadata":{"id":"98rgZG-YMRs-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739365453585,"user_tz":180,"elapsed":763,"user":{"displayName":"Karoline Farias","userId":"07244923965688739469"}},"outputId":"029e3a3f-03b9-4d50-8a59-e436efe892e1"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Correlação com o target:\n"," sepal_length    0.782561\n","sepal_width    -0.426658\n","petal_length    0.949035\n","petal_width     0.956547\n","dtype: float64\n","Features selecionadas (SelectKBest):\n"," Index(['petal_length', 'petal_width'], dtype='object')\n","Importância das features (RandomForest):\n"," sepal_length    0.096252\n","sepal_width     0.023092\n","petal_length    0.493149\n","petal_width     0.387507\n","dtype: float64\n"]}]},{"cell_type":"markdown","source":["## Conclusão\n","\n","A Engenharia de Features é uma etapa crucial para o sucesso de modelos de machine learning. Através da **normalização**, **codificação** e **seleção de variáveis**, podemos preparar os dados de forma que os algoritmos consigam extrair o máximo de informação possível. Com as ferramentas certas, como Pandas e Scikit-learn, esse processo se torna simples e eficiente."],"metadata":{"id":"Dmw7DuRjREm9"}},{"cell_type":"code","source":[],"metadata":{"id":"yMp2XUPiOwl_"},"execution_count":null,"outputs":[]}]}